{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Evaluating Classification Models on Humor Styles Data\n",
    "\n",
    "---\n",
    "\n",
    "In this lab you will be practicing evaluating classification models (Logistic Regression in particular) on a \"Humor Styles\" survey.\n",
    "\n",
    "This survey is designed to evaluate what \"style\" of humor subjects have. Your goal will be to classify gender using the responses on the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Humor styles questions encoding reference\n",
    "\n",
    "### 32 questions:\n",
    "\n",
    "Subjects answered **32** different questions outlined below:\n",
    "\n",
    "    1. I usually don't laugh or joke with other people.\n",
    "    2. If I feel depressed, I can cheer myself up with humor.\n",
    "    3. If someone makes a mistake, I will tease them about it.\n",
    "    4. I let people laugh at me or make fun of me at my expense more than I should.\n",
    "    5. I don't have to work very hard to make other people laugh. I am a naturally humorous person.\n",
    "    6. Even when I'm alone, I am often amused by the absurdities of life.\n",
    "    7. People are never offended or hurt by my sense of humor.\n",
    "    8. I will often get carried away in putting myself down if it makes family or friends laugh.\n",
    "    9. I rarely make other people laugh by telling funny stories about myself.\n",
    "    10. If I am feeling upset or unhappy I usually try to think of something funny about the situation to make myself feel better.\n",
    "    11. When telling jokes or saying funny things, I am usually not concerned about how other people are taking it.\n",
    "    12. I often try to make people like or accept me more by saying something funny about my own weaknesses, blunders, or faults.\n",
    "    13. I laugh and joke a lot with my closest friends.\n",
    "    14. My humorous outlook on life keeps me from getting overly upset or depressed about things.\n",
    "    15. I do not like it when people use humor as a way of criticizing or putting someone down.\n",
    "    16. I don't often say funny things to put myself down.\n",
    "    17. I usually don't like to tell jokes or amuse people.\n",
    "    18. If I'm by myself and I'm feeling unhappy, I make an effort to think of something funny to cheer myself up.\n",
    "    19. Sometimes I think of something that is so funny that I can't stop myself from saying it, even if it is not appropriate for the situation.\n",
    "    20. I often go overboard in putting myself down when I am making jokes or trying to be funny.\n",
    "    21. I enjoy making people laugh.\n",
    "    22. If I am feeling sad or upset, I usually lose my sense of humor.\n",
    "    23. I never participate in laughing at others even if all my friends are doing it.\n",
    "    24. When I am with friends or family, I often seem to be the one that other people make fun of or joke about.\n",
    "    25. I don√≠t often joke around with my friends.\n",
    "    26. It is my experience that thinking about some amusing aspect of a situation is often a very effective way of coping with problems.\n",
    "    27. If I don't like someone, I often use humor or teasing to put them down.\n",
    "    28. If I am having problems or feeling unhappy, I often cover it up by joking around, so that even my closest friends don't know how I really feel.\n",
    "    29. I usually can't think of witty things to say when I'm with other people.\n",
    "    30. I don't need to be with other people to feel amused. I can usually find things to laugh about even when I'm by myself.\n",
    "    31. Even if something is really funny to me, I will not laugh or joke about it if someone will be offended.\n",
    "    32. Letting others laugh at me is my way of keeping my friends and family in good spirits.\n",
    "\n",
    "---\n",
    "\n",
    "### Response scale:\n",
    "\n",
    "For each question, there are 5 possible response codes (\"likert scale\") that correspond to different answers. There is also a code that indicates there is no response for that subject.\n",
    "\n",
    "    1 == \"Never or very rarely true\"\n",
    "    2 == \"Rarely true\"\n",
    "    3 == \"Sometimes true\"\n",
    "    4 == \"Often true\"\n",
    "    5 == \"Very often or always true\n",
    "    [-1 == Did not select an answer]\n",
    "    \n",
    "---\n",
    "\n",
    "### Demographics:\n",
    "\n",
    "    age: entered as as text then parsed to an interger.\n",
    "    gender: chosen from drop down list (1=male, 2=female, 3=other, 0=declined)\n",
    "    accuracy: How accurate they thought their answers were on a scale from 0 to 100, answers were entered as text and parsed to an integer. They were instructed to enter a 0 if they did not want to be included in research.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data and perform any EDA and cleaning you think is necessary.\n",
    "\n",
    "It is worth reading over the description of the data columns above for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hsq = pd.read_csv('./hsq_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# correct spelling\n",
    "hsq.rename(columns={'agressive':'aggressive'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1071, 39)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 3 0]\n",
      "1    581\n",
      "2    477\n",
      "3      8\n",
      "0      5\n",
      "Name: gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# looks like there are 4 genders but most are just male and female\n",
    "print hsq.gender.unique()\n",
    "print hsq.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set any of the -1 values in the question answers to np.nan\n",
    "for col in [c for c in hsq.columns if c.startswith('Q')]:\n",
    "    hsq[col] = hsq[col].map(lambda x: np.nan if x == -1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1                3\n",
       "Q2                3\n",
       "Q3                2\n",
       "Q4                1\n",
       "Q5                2\n",
       "Q6                2\n",
       "Q7                2\n",
       "Q8                7\n",
       "Q9                4\n",
       "Q10               3\n",
       "Q11               2\n",
       "Q12               2\n",
       "Q13               2\n",
       "Q14               4\n",
       "Q15               7\n",
       "Q16               5\n",
       "Q17              13\n",
       "Q18               6\n",
       "Q19               4\n",
       "Q20               6\n",
       "Q21               8\n",
       "Q22               7\n",
       "Q23               8\n",
       "Q24               7\n",
       "Q25              10\n",
       "Q26               9\n",
       "Q27               5\n",
       "Q28               4\n",
       "Q29               6\n",
       "Q30               8\n",
       "Q31               7\n",
       "Q32               3\n",
       "affiliative       0\n",
       "selfenhancing     0\n",
       "aggressive        0\n",
       "selfdefeating     0\n",
       "age               0\n",
       "gender            0\n",
       "accuracy          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values:\n",
    "hsq.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(993, 39)\n"
     ]
    }
   ],
   "source": [
    "# drop the nulls\n",
    "hsq.dropna(inplace=True)\n",
    "print hsq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   25,    44,    50,    52,    30,    27,    34,    18,    33,\n",
       "          26,    36,    21,    20,    23,    70,    17,    39,    61,\n",
       "          29,    16,    69,    22,    38,    24,    14,    40,    62,\n",
       "          51,    35,    46,    42,    19,    32,    15,    37,    45,\n",
       "          28,    49,    31,    64,    54,    68,    48,    60,    43,\n",
       "          41,    53,    58,   242,   151,    55,    67,    56,    59,\n",
       "          66,    47,  2670,    57, 44849])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsq.age.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set hsq to be only valid ages:\n",
    "hsq = hsq[hsq.age <= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only keep male and female\n",
    "hsq = hsq[hsq.gender.isin([1,2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set up a predictor matrix to predict `gender` (only male vs. female)\n",
    "\n",
    "Choice of predictors is up to you. Justify which variables you include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30', 'Q31', 'Q32', 'age', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "# not including the \"aggregate\" measures (affiliative, selfenhancing, etc.) as they are combinations\n",
    "# of the original questions.\n",
    "predictors = [x for x in hsq.columns if 'Q' in x]\n",
    "predictors = predictors + ['age', 'accuracy']\n",
    "print predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up y variable\n",
    "y = hsq.gender.map(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = hsq[predictors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. StandardScaler to normalise your data and Fit a Logistic Regression model and compare your cross-validated accuracy to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6       ,  0.6       ,  0.625     ,  0.625     ,  0.675     ,\n",
       "        0.625     ,  0.675     ,  0.575     ,  0.525     ,  0.625     ,\n",
       "        0.53846154,  0.66666667,  0.46153846,  0.64102564,  0.64102564,\n",
       "        0.56410256,  0.71794872,  0.44736842,  0.65789474,  0.65789474,\n",
       "        0.71052632,  0.63157895,  0.57894737,  0.44736842,  0.63157895])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10**6)\n",
    "cross_val_score(lr, X, y, cv=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5475946775844421"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a 50-50 train-test split. Fit the model on training and get the predictions and predicted probabilities on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A:\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.5)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhat = lr.predict(X_test)\n",
    "yhat_pp = lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1]\n",
      "[[ 0.71179952  0.28820048]\n",
      " [ 0.66983916  0.33016084]\n",
      " [ 0.63031039  0.36968961]\n",
      " [ 0.82007952  0.17992048]\n",
      " [ 0.19673802  0.80326198]]\n"
     ]
    }
   ],
   "source": [
    "print yhat[:5]\n",
    "print yhat_pp[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Manually calculate the true positives, false positives, true negatives, and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 93 115 108\n"
     ]
    }
   ],
   "source": [
    "# A:\n",
    "tp = np.sum((y_test == 1) & (yhat == 1))\n",
    "fp = np.sum((y_test == 0) & (yhat == 1))\n",
    "tn = np.sum((y_test == 0) & (yhat == 0))\n",
    "fn = np.sum((y_test == 1) & (yhat == 0))\n",
    "print tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Construct the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n",
    "confusion_matrix_ = [[tp,fp],[fn,tn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_male</th>\n",
       "      <th>is_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted_male</th>\n",
       "      <td>173</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_female</th>\n",
       "      <td>108</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  is_male  is_female\n",
       "predicted_male        173         93\n",
       "predicted_female      108        115"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conmat = np.array(confusion_matrix(y_test, yhat, labels=[1,0]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['is_male', 'is_female'],\n",
    "                         columns=['predicted_male','predicted_female'])\n",
    "confusion.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Print out the false positive count as you change your threshold for predicting label 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.711800</td>\n",
       "      <td>0.288200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.669839</td>\n",
       "      <td>0.330161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.630310</td>\n",
       "      <td>0.369690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.820080</td>\n",
       "      <td>0.179920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.196738</td>\n",
       "      <td>0.803262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     female      male\n",
       "0  0.711800  0.288200\n",
       "1  0.669839  0.330161\n",
       "2  0.630310  0.369690\n",
       "3  0.820080  0.179920\n",
       "4  0.196738  0.803262"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = pd.DataFrame(yhat_pp, columns = ['female', 'male'])\n",
    "pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1 false positives: 207\n",
      "Threshold: 0.2 false positives: 196\n",
      "Threshold: 0.3 false positives: 173\n",
      "Threshold: 0.4 false positives: 130\n",
      "Threshold: 0.5 false positives: 93\n",
      "Threshold: 0.6 false positives: 57\n",
      "Threshold: 0.7 false positives: 32\n",
      "Threshold: 0.8 false positives: 10\n",
      "Threshold: 0.9 false positives: 2\n"
     ]
    }
   ],
   "source": [
    "for thresh in np.arange(1,10)/10.:\n",
    "    labeled_male = np.array([1 if x >= thresh else 0 for x in pp.male.values])\n",
    "    print 'Threshold:', thresh, 'false positives:', np.sum((y_test == 0) & (labeled_male == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Plot an ROC curve using your predicted probabilities on the test data.\n",
    "\n",
    "Calculate the area under the curve.\n",
    "\n",
    "> *Hint: go back to the lecture to find code for plotting the ROC curve.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-0e693a7e2549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mactuals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "actuals = lr.predict() \n",
    "probas = lr.predict_proba(feature_set)\n",
    "plt.plot(roc_curve(tp), roc_curve(tn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Cross-validate a logistic regression with grid search\n",
    "\n",
    "Logistic regression can also use the Ridge penalty. Sklearn's `LogisticRegressionCV` class will help you cross-validate an appropriate regularization strength.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e764f34f6d51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'estimator' is not defined"
     ]
    }
   ],
   "source": [
    "estimator.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got estimator LogisticRegression(C=1000000, class_weight=None, dual=False,\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\n          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-0175df9de036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     scoring = 'mean_squared_error')\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/patrickbrown/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \"\"\"\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrickbrown/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrickbrown/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Don't get num_samples from an ensembles length!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         raise TypeError('Expected sequence or array-like, got '\n\u001b[0;32m--> 116\u001b[0;31m                         'estimator %s' % x)\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__array__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got estimator LogisticRegression(C=1000000, class_weight=None, dual=False,\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\n          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
     ]
    }
   ],
   "source": [
    "from sklearn import grid_search\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "n_samples = len(X_test)\n",
    "\n",
    "alphas = np.logspace(-10,10,21)\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator = Ridge(),\n",
    "    param_grid = {'alpha': alphas},\n",
    "    scoring = 'mean_squared_error')\n",
    "\n",
    "gs.fit(lr,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-d4b5377bad6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ridge' is not defined"
     ]
    }
   ],
   "source": [
    "ridge.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.B Calculate the predicted labels and predicted probabilities on the test set with the Ridge logisitic regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.C Construct the confusion matrix for the Ridge LR.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Plot the ROC curve for the original and Ridge logistic regressions on the same plot.\n",
    "\n",
    "Which performs better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Cross-validate a Lasso logistic regression.\n",
    "\n",
    "**Remember:**\n",
    "- `penalty` must be set to `'l1'`\n",
    "- `solver` must be set to `'liblinear'`\n",
    "\n",
    "> **Note:** The lasso penalty can be considerably slower. You may want to try fewer Cs or use fewer cv folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Make the confusion matrix for the Lasso model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Plot all three logistic regression models on the same ROC plot.\n",
    "\n",
    "Which is the best? (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Look at the coefficients for the Lasso logistic regression model. Which variables are the most important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
